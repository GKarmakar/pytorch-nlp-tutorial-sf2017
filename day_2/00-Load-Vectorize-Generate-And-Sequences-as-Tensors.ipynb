{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from local_settings import settings, datautils\n",
    "\n",
    "from datautils.vocabulary import Vocabulary\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import FloatTensor\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures\n",
    "\n",
    "For the notebooks presented today, we will be using a pattern that we have employed many times.  For this, we break the machine learning data pipeline into 4 distinct parts:\n",
    "\n",
    "1. Raw Data\n",
    "2. Vectorized Data\n",
    "3. A Vectorizer\n",
    "4. A (python) generator\n",
    "\n",
    "To give it a name, I'll called it Load-Vectorize-Generate (LVG)\n",
    "\n",
    "This pipeline turns letters or words into integers and then batches them to yield matrices of integers.  For language, since it is variable length, there are also 0-valued positions in the matrix. we will see how we tell PyTorch to treat these 0s as ignore-values.  \n",
    "\n",
    "After I introduce LVG, I will show quickly how to use the data generated from LVG ( a matrix of integers ). First, it is embedded so a vector of numbers is associated with each integer, then the batch is put on the 0th dimension so that it can be iterated over. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load\n",
    "\n",
    "Loading the raw data from disk should be relatively quickly.  Preferably, all munging should have happened & the form that is loaded should have precomputed things like split (between train/test/eval or fold #).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RawSurnames(object):\n",
    "    def __init__(self, data_path=settings.SURNAMES_CSV, delimiter=\",\"):\n",
    "        self.data = pd.read_csv(data_path, delimiter=delimiter)\n",
    "\n",
    "    def get_data(self, filter_to_nationality=None):\n",
    "        if filter_to_nationality is not None:\n",
    "            return self.data[self.data.nationality.isin(filter_to_nationality)]\n",
    "        return self.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize\n",
    "\n",
    "The first class is here is for managing the vectorized data structure.  It subclasses PyTorch's dataset class, which is supposed to implement two functions: `__len__` and `__getitem__`.  Our assumption with this is that no data processing is happening here; it is given the final tensors at init time and it just provides them through `__getitem__`.  PyTorch has things available to use this for sophisticated data queueing with the `DataLoader` class.  The `DataLoader` class will also convert these structures into PyTorch tensors, so we don't have to do that conversion. \n",
    "\n",
    "Some additional things: we also are returning the lengths of the sequences so that we can use them in the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VectorizedSurnames(Dataset):\n",
    "    def __init__(self, x_surnames, y_nationalities):\n",
    "        self.x_surnames = x_surnames\n",
    "        self.y_nationalities = y_nationalities\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_surnames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {'x_surnames': self.x_surnames[index],\n",
    "                'y_nationalities': self.y_nationalities[index],\n",
    "                'x_lengths': len(self.x_surnames[index].nonzero()[0])}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizer\n",
    "\n",
    "The actual vectorizer has a lot of responsibility.  \n",
    "\n",
    "Primarily, it manages the Vocabulary object, saving and loading it, and applying it to a dataset to create a vectorized form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SurnamesVectorizer(object):\n",
    "    def __init__(self, surname_vocab, nationality_vocab, max_seq_length):\n",
    "        self.surname_vocab = surname_vocab\n",
    "        self.nationality_vocab = nationality_vocab\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "    def save(self, filename):\n",
    "        vec_dict = {\"surname_vocab\": self.surname_vocab.get_serializable_contents(),\n",
    "                    \"nationality_vocab\": self.nationality_vocab.get_serializable_contents(),\n",
    "                    'max_seq_length': self.max_seq_length}\n",
    "\n",
    "        with open(filename, \"w\") as fp:\n",
    "            json.dump(vec_dict, fp)\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        with open(filename, \"r\") as fp:\n",
    "            vec_dict = json.load(fp)\n",
    "\n",
    "        vec_dict[\"surname_vocab\"] = Vocabulary.deserialize_from_contents(vec_dict[\"surname_vocab\"])\n",
    "        vec_dict[\"nationality_vocab\"] = Vocabulary.deserialize_from_contents(vec_dict[\"nationality_vocab\"])\n",
    "        return cls(**vec_dict)\n",
    "\n",
    "    @classmethod\n",
    "    def fit(cls, surname_df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        surname_vocab = Vocabulary(use_unks=False,\n",
    "                                   use_mask=True,\n",
    "                                   use_start_end=True,\n",
    "                                   start_token=settings.START_TOKEN,\n",
    "                                   end_token=settings.END_TOKEN)\n",
    "\n",
    "        nationality_vocab = Vocabulary(use_unks=False, use_start_end=False, use_mask=False)\n",
    "\n",
    "        max_seq_length = 0\n",
    "        for index, row in surname_df.iterrows():\n",
    "            surname_vocab.add_many(row.surname)\n",
    "            nationality_vocab.add(row.nationality)\n",
    "\n",
    "            if len(row.surname) > max_seq_length:\n",
    "                max_seq_length = len(row.surname)\n",
    "        max_seq_length = max_seq_length + 2\n",
    "\n",
    "        return cls(surname_vocab, nationality_vocab, max_seq_length)\n",
    "\n",
    "    @classmethod\n",
    "    def fit_transform(cls, surname_df, split='train'):\n",
    "        vectorizer = cls.fit(surname_df)\n",
    "        return vectorizer, vectorizer.transform(surname_df, split)\n",
    "\n",
    "    def transform(self, surname_df, split='train'):\n",
    "\n",
    "        df = surname_df[surname_df.split==split].reset_index()\n",
    "        n_data = len(df)\n",
    "        \n",
    "        x_surnames = np.zeros((n_data, self.max_seq_length), dtype=np.int64)\n",
    "        y_nationalities = np.zeros(n_data, dtype=np.int64)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            vectorized_surname = list(self.surname_vocab.map(row.surname, \n",
    "                                                             include_start_end=True))\n",
    "            x_surnames[index, :len(vectorized_surname)] = vectorized_surname\n",
    "            y_nationalities[index] = self.nationality_vocab[row.nationality]\n",
    "\n",
    "        return VectorizedSurnames(x_surnames, y_nationalities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate\n",
    "\n",
    "Finally, the make_data_generator interacts with PyTorch's `DataLoader` and returns a generator. It basically just iterates over the `DataLoader` generator and does some processing.  Currently, it returns a function rather than just making the generator itself so some control can be had over num_batches & volatile mode, and other run time things. It's mostly a cheap and easy function that can be written in many ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data generator\n",
    "\n",
    "def make_generator(vectorized_data, batch_size, num_batches=-1, \n",
    "                               num_workers=0, volatile_mode=False, \n",
    "                               strict_batching=True):\n",
    "\n",
    "    loaded_data = DataLoader(vectorized_data, batch_size=batch_size, \n",
    "                             shuffle=True, num_workers=num_workers)\n",
    "\n",
    "    def inner_func(num_batches=num_batches, \n",
    "                   volatile_mode=volatile_mode):\n",
    "\n",
    "        for batch_index, batch in enumerate(loaded_data):\n",
    "            out = {}\n",
    "            current_batch_size = list(batch.values())[0].size(0)\n",
    "            if current_batch_size < batch_size and strict_batching:\n",
    "                break\n",
    "            for key, value in batch.items():\n",
    "                if not isinstance(value, Variable):\n",
    "                    value = Variable(value)\n",
    "                if settings.CUDA:\n",
    "                    value = value.cuda()\n",
    "                if volatile_mode:\n",
    "                    value = value.volatile()\n",
    "                out[key] = value\n",
    "            yield out\n",
    "\n",
    "            if num_batches > 0 and batch_index > num_batches:\n",
    "                break\n",
    "\n",
    "    return inner_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = RawSurnames().get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>surname</th>\n",
       "      <th>nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>Hadad</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>Prikazchikov</td>\n",
       "      <td>russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>Bajov</td>\n",
       "      <td>russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>Awduewsky</td>\n",
       "      <td>russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>Jablochkov</td>\n",
       "      <td>russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split       surname nationality\n",
       "0  train         Hadad      arabic\n",
       "1  train  Prikazchikov     russian\n",
       "2  train         Bajov     russian\n",
       "3  train     Awduewsky     russian\n",
       "4  train    Jablochkov     russian"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Vocabulary(size=18,frozen=False)>, <Vocabulary(size=90,frozen=False)>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = SurnamesVectorizer.fit(raw_data)\n",
    "\n",
    "vectorizer.nationality_vocab, vectorizer.surname_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_train = vectorizer.transform(raw_data, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  3,  4, ...,  0,  0,  0],\n",
       "        [ 1,  6,  7, ...,  0,  0,  0],\n",
       "        [ 1, 15,  4, ...,  0,  0,  0],\n",
       "        ..., \n",
       "        [ 1, 44, 12, ...,  0,  0,  0],\n",
       "        [ 1, 17, 26, ...,  0,  0,  0],\n",
       "        [ 1, 32,  4, ...,  0,  0,  0]]), (16059, 22))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_train.x_surnames, vec_train.x_surnames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 1, ..., 1, 1, 1]), (16059,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_train.y_nationalities, vec_train.y_nationalities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 22)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's say we are making a randomized batch. \n",
    "n_data = len(vec_train)\n",
    "indices = np.random.choice(np.arange(n_data), \n",
    "                           size=n_data, \n",
    "                           replace=False)\n",
    "\n",
    "batch_indices = indices[:10]\n",
    "batched_x = vec_train.x_surnames[batch_indices]\n",
    "batched_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding sequences\n",
    "\n",
    "Let's take a look at how sequences are embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import LongTensor\n",
    "from torch.autograd import Variable\n",
    "\n",
    "n_surnames = len(vectorizer.surname_vocab)\n",
    "# padding_idx is very important!\n",
    "emb = torch.nn.Embedding(embedding_dim=8, num_embeddings=n_surnames, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 22, 8])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_x = Variable(LongTensor(batched_x))\n",
    "x_seq = emb(torch_x)\n",
    "x_seq.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Pattern: putting sequence dimension on dimension 0\n",
    "\n",
    "Because dimension 0 is indexed faster, and it's easier to write code for, many times the dimensions are permuted to put the sequence on the first dimension. this is done like the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 10, 8])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where this swaps 1 and 0. if we did it twice, it would swap back. \n",
    "x_seq_on_dim0 = x_seq.permute(1, 0, 2)\n",
    "x_seq_on_dim0.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, later when we want to get the 5th item in the sequence, we can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_5th_step = x_seq_on_dim0[4, :, :]\n",
    "x_5th_step.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, this is the gist of how we will be using sequences as tensors.  we construct a matrix of embedding integers, use an embedding module to retrieve their corresponding vectors, and then move the sequence to the first dimension so we can index into it easier & faster. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t3",
   "language": "python",
   "name": "t3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
